#!/usr/bin/env python3
"""
æŠ•èµ„ç»„åˆæ»šåŠ¨çª—å£ç¨³å¥æ€§éªŒè¯å™¨ï¼ˆç®€åŒ–ç‰ˆ - ä¸€è‡´æ€§åˆ†æï¼‰

åŠŸèƒ½ï¼š
- åœ¨ä¸åŒæ—¶é—´çª—å£ï¼ˆå¦‚æ¯å¹´ï¼‰è¿è¡Œä¼˜åŒ–å™¨
- åˆ†æå“ªäº›ç»„åˆèƒ½åœ¨å¤šä¸ªæ—¶æœŸä¿æŒé«˜å¤æ™®
- è¯†åˆ«çœŸæ­£ç©¿è¶Šå‘¨æœŸçš„ç¨³å¥ç»„åˆ

ç”¨æ³•ç¤ºä¾‹ï¼š
    python rolling_portfolio_validator.py --timeframe d1 --window-months 12 --step-months 12 --workers auto

ä½œè€…ï¼šClaude Code
æ—¥æœŸï¼š2026-01-11
"""

import argparse
import os
import sys
import time
import warnings
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple
import multiprocessing as mp

import pandas as pd
import numpy as np

# å¯¼å…¥ä¼˜åŒ–å™¨
from portfolio_optimizer import optimize_programmatically

warnings.filterwarnings('ignore')


class RollingPortfolioValidator:
    """æŠ•èµ„ç»„åˆæ»šåŠ¨çª—å£ç¨³å¥æ€§éªŒè¯å™¨ï¼ˆä¸€è‡´æ€§åˆ†æç‰ˆæœ¬ï¼‰"""

    def __init__(
        self,
        timeframe: str = 'd1',
        window_months: int = 12,
        step_months: int = 12,
        results_dir: str = 'backtest_results',
        output_dir: str = 'backtest_results/rolling_validation',
        n_workers: int = 1,
        penetration_threshold: float = 0.5,
        min_recommend_freq: float = 0.0,
        sorting_mode: str = 'robustness',
        min_sharpe: float = 0.5,
        min_return: float = 1.0,
        max_drawdown: float = -10.0,
        correlation_threshold: float = 0.3,
        min_strategies: int = 2,
        max_strategies: int = 4
    ):
        """åˆå§‹åŒ–"""
        self.timeframe = timeframe
        self.window_months = window_months
        self.step_months = step_months
        self.results_dir = results_dir
        self.output_dir = output_dir
        self.n_workers = n_workers
        self.penetration_threshold = penetration_threshold
        self.min_recommend_freq = min_recommend_freq
        self.sorting_mode = sorting_mode
        self._degraded_mode = False  # é™çº§æ¨¡å¼æ ‡è®°

        # ä¼˜åŒ–å™¨å‚æ•°
        self.optimizer_params = {
            'min_sharpe': min_sharpe,
            'min_return': min_return,
            'max_drawdown': max_drawdown,
            'correlation_threshold': correlation_threshold,
            'min_strategies': min_strategies,
            'max_strategies': max_strategies
        }

        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        # æ£€æµ‹æ•°æ®èŒƒå›´
        self.data_start, self.data_end = self._detect_data_range()

    def _detect_data_range(self) -> Tuple[str, str]:
        """æ£€æµ‹å¯ç”¨æ•°æ®çš„æ—¶é—´èŒƒå›´"""
        import glob

        pattern = f"{self.results_dir}/daily_values_*_{self.timeframe}_*.csv"
        files = glob.glob(pattern)

        if not files:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½• daily_values æ–‡ä»¶")
            return '20200101', '20241231'

        # ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸ
        dates = []
        for file in files:
            parts = Path(file).stem.split('_')
            if len(parts) >= 5:
                try:
                    start_date = parts[-2]
                    end_date = parts[-1]
                    dates.append((start_date, end_date))
                except:
                    continue

        if not dates:
            return '20200101', '20241231'

        all_starts = [d[0] for d in dates]
        all_ends = [d[1] for d in dates]

        return min(all_starts), max(all_ends)

    def generate_windows(self) -> List[Dict]:
        """ç”Ÿæˆæ‰€æœ‰æ»šåŠ¨çª—å£"""
        windows = []
        window_id = 1

        start = datetime.strptime(self.data_start, '%Y%m%d')
        end = datetime.strptime(self.data_end, '%Y%m%d')

        current_start = start
        while True:
            window_end = current_start + timedelta(days=30 * self.window_months)

            if window_end > end:
                break

            windows.append({
                'window_id': window_id,
                'start_date': current_start.strftime('%Y%m%d'),
                'end_date': window_end.strftime('%Y%m%d')
            })

            window_id += 1
            current_start = current_start + timedelta(days=30 * self.step_months)

        return windows

    def run_window_optimization(self, window: Dict, top_n: int = 10) -> pd.DataFrame:
        """åœ¨æŒ‡å®šçª—å£è¿è¡Œä¼˜åŒ–å™¨"""
        start_date = window['start_date']
        end_date = window['end_date']

        try:
            portfolios_df = optimize_programmatically(
                start_date=start_date,
                end_date=end_date,
                timeframe=self.timeframe,
                **self.optimizer_params,
                results_dir=self.results_dir,
                quiet=True,
                data_start_date=self.data_start,  # ä½¿ç”¨å®Œæ•´æ•°æ®èŒƒå›´åŒ¹é…æ–‡ä»¶å
                data_end_date=self.data_end       # æ•°æ®ä¼šè¢«è‡ªåŠ¨è¿‡æ»¤åˆ°çª—å£èŒƒå›´
            )

            if portfolios_df is None or len(portfolios_df) == 0:
                return pd.DataFrame()

            portfolios_df = portfolios_df.head(top_n).copy()
            portfolios_df['window_id'] = window['window_id']
            portfolios_df['window_start'] = start_date
            portfolios_df['window_end'] = end_date

            return portfolios_df

        except Exception as e:
            print(f"  é”™è¯¯: {str(e)}")
            return pd.DataFrame()

    def calculate_robustness_metrics(self, all_windows_results: List[pd.DataFrame]) -> pd.DataFrame:
        """è®¡ç®—ç¨³å¥æ€§æŒ‡æ ‡"""
        all_portfolios = pd.concat(all_windows_results, ignore_index=True)

        if len(all_portfolios) == 0:
            return pd.DataFrame()

        def make_combo_id(strategies_str):
            if pd.isna(strategies_str):
                return 'unknown'
            strategies = sorted(str(strategies_str).split(','))
            return ','.join(strategies)

        all_portfolios['combo_id'] = all_portfolios['strategies'].apply(make_combo_id)

        total_windows = all_portfolios['window_id'].nunique()

        robustness_list = []
        for combo_id, group in all_portfolios.groupby('combo_id'):
            # ä½¿ç”¨æ­£ç¡®çš„åˆ—åï¼šexpected_sharpeï¼ˆæ¥è‡ªportfolio_optimizerï¼‰
            sharpes = group['expected_sharpe'].values

            recommend_count = len(group)
            recommend_freq = recommend_count / total_windows
            avg_sharpe = np.mean(sharpes)
            sharpe_std = np.std(sharpes)
            worst_sharpe = np.min(sharpes)
            best_sharpe = np.max(sharpes)
            penetration_count = np.sum(sharpes > self.penetration_threshold)
            penetration_rate = penetration_count / recommend_count

            worst_penalty = abs(worst_sharpe) if worst_sharpe < 0 else 0
            robustness_score = (
                0.3 * avg_sharpe +
                0.25 * penetration_rate +
                0.25 * recommend_freq -
                0.15 * sharpe_std -
                0.05 * worst_penalty
            )

            strategies = group.iloc[0]['strategies']
            num_strategies = len(str(strategies).split(','))

            # ğŸ†• é€‰æ‹©æœ€ä½³æƒé‡é…ç½®ï¼ˆå¤æ™®æœ€é«˜çš„é‚£ä¸ªï¼‰
            best_config_idx = group['expected_sharpe'].idxmax()
            best_config = group.loc[best_config_idx]

            # ğŸ†• è§£ææƒé‡ä¿¡æ¯
            weights_str = best_config.get('weights', '')
            weight_method = best_config.get('weight_method', '')

            robustness_record = {
                'combo_id': combo_id,
                'num_strategies': num_strategies,
                'strategies': strategies,
                'weights': weights_str,
                'weight_method': weight_method,
                'recommend_count': recommend_count,
                'recommend_freq': recommend_freq,
                'avg_sharpe': avg_sharpe,
                'sharpe_std': sharpe_std,
                'worst_sharpe': worst_sharpe,
                'best_sharpe': best_sharpe,
                'penetration_rate': penetration_rate,
                'robustness_score': robustness_score,
                'config_expected_sharpe': best_config.get('expected_sharpe', 0),
                'config_expected_return': best_config.get('expected_return', 0),
                'config_expected_max_dd': best_config.get('expected_max_dd', 0),
                'config_window': f"{best_config.get('window_start', '')}-{best_config.get('window_end', '')}"
            }

            # ğŸ†• æ·»åŠ åˆ†åˆ—çš„ç­–ç•¥å’Œæƒé‡ï¼ˆä¾¿äºgenerate_portfolio_atomsä½¿ç”¨ï¼‰
            if weights_str:
                strategies_list = [s.strip() for s in str(strategies).split(',')]
                weights_list = [float(w.strip()) for w in str(weights_str).split(',')]

                for i, (strat, weight) in enumerate(zip(strategies_list, weights_list), 1):
                    robustness_record[f'strategy_{i}'] = strat
                    robustness_record[f'weight_{i}'] = weight

            robustness_list.append(robustness_record)

        robustness_df = pd.DataFrame(robustness_list)

        # æ ¹æ®æ’åºæ¨¡å¼é€‰æ‹©ä¸åŒé€»è¾‘
        if self.sorting_mode == 'threshold':
            # é˜ˆå€¼ç­›é€‰æ³•ï¼šå…ˆç­›é€‰æ¨èé¢‘ç‡ï¼Œå†æŒ‰å¹³å‡å¤æ™®æ’åº
            print(f"\nã€ç­›é€‰æ¨¡å¼ã€‘é˜ˆå€¼ç­›é€‰æ³•")
            print(f"  æ¨èé¢‘ç‡é˜ˆå€¼: {self.min_recommend_freq*100:.0f}%")

            # ç¬¬1æ­¥ï¼šæŒ‰æ¨èé¢‘ç‡ç­›é€‰
            filtered_df = robustness_df[robustness_df['recommend_freq'] >= self.min_recommend_freq]
            print(f"  ç­›é€‰å‰ç»„åˆæ•°: {len(robustness_df)}")
            print(f"  ç­›é€‰åç»„åˆæ•°: {len(filtered_df)}")

            if len(filtered_df) == 0:
                print(f"  âš ï¸  è­¦å‘Š: æ²¡æœ‰ç»„åˆæ»¡è¶³æ¨èé¢‘ç‡â‰¥{self.min_recommend_freq*100:.0f}%")
                print(f"  é™çº§ç­–ç•¥: æŒ‰æ¨èé¢‘ç‡é™åºæ’åˆ—ï¼Œæ˜¾ç¤ºæœ€æ¥è¿‘é˜ˆå€¼çš„ç»„åˆ")
                # é™çº§ï¼šæŒ‰æ¨èé¢‘ç‡é™åºï¼Œå†æŒ‰å¹³å‡å¤æ™®æ’åº
                filtered_df = robustness_df.sort_values(['recommend_freq', 'avg_sharpe'], ascending=[False, False])
                # æ ‡è®°é™çº§çŠ¶æ€
                self._degraded_mode = True
            else:
                # ç¬¬2æ­¥ï¼šæŒ‰å¹³å‡å¤æ™®æ’åº
                filtered_df = filtered_df.sort_values('avg_sharpe', ascending=False)
                self._degraded_mode = False

            filtered_df = filtered_df.reset_index(drop=True)
            filtered_df['rank'] = range(1, len(filtered_df) + 1)
            return filtered_df

        elif self.sorting_mode == 'robustness':
            # ç»¼åˆè¯„åˆ†æ³•ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            print(f"\nã€ç­›é€‰æ¨¡å¼ã€‘ç»¼åˆè¯„åˆ†æ³•ï¼ˆrobustness_scoreï¼‰")
            robustness_df = robustness_df.sort_values('robustness_score', ascending=False)
            robustness_df.reset_index(drop=True, inplace=True)
            robustness_df['rank'] = range(1, len(robustness_df) + 1)
            self._degraded_mode = False
            return robustness_df

        else:
            raise ValueError(f"æœªçŸ¥çš„æ’åºæ¨¡å¼: {self.sorting_mode}")

    def run_rolling_validation(self, top_n_per_window: int = 10, use_parallel: bool = True) -> Dict:
        """è¿è¡Œå®Œæ•´çš„æ»šåŠ¨éªŒè¯æµç¨‹"""
        print("=" * 80)
        print("æŠ•èµ„ç»„åˆæ»šåŠ¨çª—å£ç¨³å¥æ€§éªŒè¯ï¼ˆä¸€è‡´æ€§åˆ†æï¼‰")
        print("=" * 80)
        print(f"é…ç½®:")
        print(f"  æ—¶é—´å‘¨æœŸ: {self.timeframe}")
        print(f"  çª—å£é•¿åº¦: {self.window_months}ä¸ªæœˆ")
        print(f"  æ»‘åŠ¨æ­¥é•¿: {self.step_months}ä¸ªæœˆ")
        print(f"  æ•°æ®èŒƒå›´: {self.data_start[:4]}-{self.data_start[4:6]} è‡³ {self.data_end[:4]}-{self.data_end[4:6]}")
        print("=" * 80)
        print("")

        print("ç”Ÿæˆçª—å£...")
        windows = self.generate_windows()
        print(f"  å…±ç”Ÿæˆ {len(windows)} ä¸ªæ»šåŠ¨çª—å£")
        print("")

        if len(windows) == 0:
            print("é”™è¯¯: æ— æ³•ç”Ÿæˆçª—å£")
            return {'summary': pd.DataFrame(), 'robust_ranking': pd.DataFrame(), 'all_windows': []}

        start_time = time.time()

        if use_parallel and self.n_workers > 1:
            all_results = self._run_parallel(windows, top_n_per_window)
        else:
            all_results = self._run_serial(windows, top_n_per_window)

        elapsed = time.time() - start_time

        print("")
        print(f"æ‰§è¡Œå®Œæˆï¼æ€»è€—æ—¶: {elapsed:.0f}ç§’")
        print("")

        robustness_df = self.calculate_robustness_metrics(all_results)

        summary_list = []
        for i, window in enumerate(windows):
            window_result = all_results[i]
            if len(window_result) > 0:
                summary_list.append({
                    'window_id': window['window_id'],
                    'start_date': window['start_date'],
                    'end_date': window['end_date'],
                    'num_portfolios': len(window_result),
                    'best_sharpe': window_result['expected_sharpe'].max(),
                    'avg_sharpe': window_result['expected_sharpe'].mean()
                })

        summary_df = pd.DataFrame(summary_list)

        return {
            'summary': summary_df,
            'robust_ranking': robustness_df,
            'all_windows': all_results
        }

    def _run_serial(self, windows: List[Dict], top_n_per_window: int) -> List[pd.DataFrame]:
        """ä¸²è¡Œæ‰§è¡Œ"""
        all_results = []

        for i, window in enumerate(windows):
            print(f"çª—å£ {i+1}/{len(windows)}: {window['start_date'][:4]}-{window['start_date'][4:6]} ~ {window['end_date'][:4]}-{window['end_date'][4:6]}")
            print(f"  è¿è¡Œä¼˜åŒ–å™¨...")

            result = self.run_window_optimization(window, top_n_per_window)

            if len(result) > 0:
                print(f"  ç”Ÿæˆ {len(result)} ä¸ªæ¨èç»„åˆ")
                best = result.iloc[0]
                print(f"  æœ€ä½³ç»„åˆ: {best.get('strategies', 'N/A')} (å¤æ™®{best.get('expected_sharpe', 0):.2f})")
            else:
                print(f"  è­¦å‘Š: æœªç”Ÿæˆä»»ä½•ç»„åˆ")

            all_results.append(result)
            print("")

        return all_results

    def _run_parallel(self, windows: List[Dict], top_n_per_window: int) -> List[pd.DataFrame]:
        """å¹¶è¡Œæ‰§è¡Œ"""
        print(f"å¯åŠ¨å¹¶è¡Œæ‰§è¡Œï¼ˆ{self.n_workers}æ ¸ï¼‰...")
        print("")

        args_list = [(self, window, top_n_per_window, i+1, len(windows)) for i, window in enumerate(windows)]

        with mp.Pool(processes=self.n_workers) as pool:
            all_results = pool.starmap(_run_window_worker, args_list)

        return all_results

    def generate_report(self, results: Dict):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        summary_df = results['summary']
        robustness_df = results['robust_ranking']

        print("=" * 80)
        print("ç¨³å¥æ€§åˆ†æç»“æœ")
        print("=" * 80)
        print("")

        if len(robustness_df) == 0:
            print("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç»„åˆ")
            return

        if self.sorting_mode == 'threshold':
            if hasattr(self, '_degraded_mode') and self._degraded_mode:
                print(f"ã€Top 5 ç¨³å¥ç»„åˆã€‘ï¼ˆé™çº§æ¨¡å¼: æŒ‰æ¨èé¢‘ç‡é™åºï¼Œæ— ç»„åˆæ»¡è¶³â‰¥{self.min_recommend_freq*100:.0f}%ï¼‰")
            else:
                print(f"ã€Top 5 ç¨³å¥ç»„åˆã€‘ï¼ˆé˜ˆå€¼ç­›é€‰æ³•: æ¨èé¢‘ç‡â‰¥{self.min_recommend_freq*100:.0f}%, æŒ‰å¹³å‡å¤æ™®æ’åºï¼‰")
        else:
            print("ã€Top 5 ç¨³å¥ç»„åˆã€‘ï¼ˆç»¼åˆè¯„åˆ†æ³•: æŒ‰robustness_scoreæ’åºï¼‰")
        print("-" * 120)
        print(f"{'æ’å':<6} {'ç­–ç•¥ç»„æˆ':<35} {'æ¨èé¢‘ç‡':<10} {'å¹³å‡å¤æ™®':<10} "
              f"{'å¤æ™®æ ‡å‡†å·®':<12} {'æœ€å·®å¤æ™®':<10} {'æœ€ä½³å¤æ™®':<10} {'ç©¿è¶Šç‡':<10} {'ç¨³å¥è¯„åˆ†':<10}")
        print("-" * 120)

        top_5 = robustness_df.head(5)
        for _, row in top_5.iterrows():
            print(f"{row['rank']:<6} {row['strategies'][:33]:<35} "
                  f"{row['recommend_freq']:>8.0%}  {row['avg_sharpe']:>10.2f} "
                  f"{row['sharpe_std']:>12.3f} {row['worst_sharpe']:>10.2f} "
                  f"{row['best_sharpe']:>10.2f} {row['penetration_rate']:>8.0%}  {row['robustness_score']:>10.3f}")

        print("")

        total_windows = len(summary_df)
        print(f"ã€ç©¿è¶Šèƒ½åŠ›åˆ†æã€‘ï¼ˆé˜ˆå€¼: å¤æ™®>{self.penetration_threshold}ï¼‰")

        all_windows_combos = robustness_df[robustness_df['recommend_count'] == total_windows]
        high_freq_combos = robustness_df[robustness_df['recommend_count'] >= total_windows * 0.8]
        mid_freq_combos = robustness_df[robustness_df['recommend_count'] >= total_windows * 0.6]

        print(f"- åœ¨æ‰€æœ‰{total_windows}ä¸ªçª—å£éƒ½è¢«æ¨èçš„ç»„åˆ: {len(all_windows_combos)}ä¸ª â­â­â­")
        print(f"- åœ¨â‰¥80%çª—å£è¢«æ¨èçš„ç»„åˆ: {len(high_freq_combos)}ä¸ª â­â­")
        print(f"- åœ¨â‰¥60%çª—å£è¢«æ¨èçš„ç»„åˆ: {len(mid_freq_combos)}ä¸ª â­")

        full_penetration = robustness_df[robustness_df['penetration_rate'] == 1.0]
        print(f"- æ‰€æœ‰å‡ºç°çª—å£éƒ½ä¿æŒå¤æ™®>{self.penetration_threshold}çš„ç»„åˆ: {len(full_penetration)}ä¸ª âœ“")
        print("")

        if len(robustness_df) > 0:
            best = robustness_df.iloc[0]
            print(f"ã€æœ€ç¨³å¥ç»„åˆè¯¦ç»†åˆ†æã€‘")
            print(f"ç»„åˆ: {best['strategies']}")
            print(f"  æ¨èé¢‘ç‡: {best['recommend_freq']:.0%} ({best['recommend_count']}/{total_windows}ä¸ªçª—å£)")
            print(f"  å¤æ™®ç¨³å®šæ€§: æ ‡å‡†å·®{best['sharpe_std']:.3f}")
            print(f"  å¹³å‡å¤æ™®: {best['avg_sharpe']:.2f}")
            print(f"  æœ€å·®å¤æ™®: {best['worst_sharpe']:.2f}")
            print(f"  æœ€ä½³å¤æ™®: {best['best_sharpe']:.2f}")
            print(f"  ç©¿è¶Šç‡: {best['penetration_rate']:.0%}")
            print("")

            if best['recommend_count'] == total_windows and best['penetration_rate'] == 1.0:
                print(f"  â†’ è¿™ä¸ªç»„åˆçœŸæ­£ç©¿è¶Šäº†æ‰€æœ‰{total_windows}ä¸ªæ—¶é—´çª—å£ï¼ â­â­â­")
            print("")

        summary_path = f"{self.output_dir}/rolling_window_summary.csv"
        robustness_path = f"{self.output_dir}/robust_portfolios_ranking.csv"

        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        robustness_df.to_csv(robustness_path, index=False, encoding='utf-8-sig')

        all_windows_df = pd.concat(results['all_windows'], ignore_index=True)
        if len(all_windows_df) > 0:
            details_path = f"{self.output_dir}/window_details.csv"
            all_windows_df.to_csv(details_path, index=False, encoding='utf-8-sig')
            print(f"ç»“æœå·²ä¿å­˜:")
            print(f"  - {summary_path}")
            print(f"  - {robustness_path} (åŒ…å«æƒé‡ä¿¡æ¯ï¼Œå¯ç›´æ¥ç”¨äºgenerate_portfolio_atoms)")
            print(f"  - {details_path}")
        else:
            print(f"ç»“æœå·²ä¿å­˜:")
            print(f"  - {summary_path}")
            print(f"  - {robustness_path} (åŒ…å«æƒé‡ä¿¡æ¯ï¼Œå¯ç›´æ¥ç”¨äºgenerate_portfolio_atoms)")
        print("")


def _run_window_worker(validator, window, top_n, window_index, total_windows):
    """Worker function for parallel execution"""
    print(f"  [{window_index}/{total_windows}] çª—å£ {window['window_id']}: "
          f"{window['start_date'][:4]}-{window['start_date'][4:6]} ~ "
          f"{window['end_date'][:4]}-{window['end_date'][4:6]}")
    return validator.run_window_optimization(window, top_n)


def main():
    parser = argparse.ArgumentParser(description='æŠ•èµ„ç»„åˆæ»šåŠ¨çª—å£ç¨³å¥æ€§éªŒè¯å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰')

    parser.add_argument('--timeframe', type=str, default='d1', help='æ—¶é—´å‘¨æœŸ')
    parser.add_argument('--window-months', type=int, default=12, help='çª—å£é•¿åº¦ï¼ˆæœˆï¼‰')
    parser.add_argument('--step-months', type=int, default=12, help='æ»‘åŠ¨æ­¥é•¿ï¼ˆæœˆï¼‰')
    parser.add_argument('--top-n', type=int, default=10, help='æ¯ä¸ªçª—å£ä¿ç•™Top Nä¸ªç»„åˆ')
    parser.add_argument('--workers', type=str, default='auto', help='å¹¶è¡Œè¿›ç¨‹æ•°')

    parser.add_argument('--min-sharpe', type=float, default=0.5, help='å¤æ™®æ¯”ç‡é˜ˆå€¼')
    parser.add_argument('--min-return', type=float, default=1.0, help='æ”¶ç›Šç‡é˜ˆå€¼')
    parser.add_argument('--max-drawdown', type=float, default=-10.0, help='æœ€å¤§å›æ’¤é˜ˆå€¼')
    parser.add_argument('--correlation-threshold', type=float, default=0.3, help='ç›¸å…³æ€§é˜ˆå€¼')
    parser.add_argument('--min-strategies', type=int, default=2, help='ç»„åˆæœ€å°‘ç­–ç•¥æ•°')
    parser.add_argument('--max-strategies', type=int, default=4, help='ç»„åˆæœ€å¤šç­–ç•¥æ•°')

    parser.add_argument('--results-dir', type=str, default='backtest_results', help='ç»“æœç›®å½•')
    parser.add_argument('--output-dir', type=str, default='backtest_results/rolling_validation', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--penetration-threshold', type=float, default=0.5, help='ç©¿è¶Šç‡é˜ˆå€¼')
    parser.add_argument('--min-recommend-freq', type=float, default=0.0,
                        help='æ¨èé¢‘ç‡é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œä»…åœ¨thresholdæ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼Œä¾‹å¦‚0.8è¡¨ç¤ºâ‰¥80%%')
    parser.add_argument('--sorting-mode', type=str, default='robustness',
                        choices=['robustness', 'threshold'],
                        help='æ’åºæ¨¡å¼: robustness=ç»¼åˆè¯„åˆ†æ³•ï¼ˆé»˜è®¤ï¼‰, threshold=é˜ˆå€¼ç­›é€‰æ³•')

    args = parser.parse_args()

    if args.workers == 'auto':
        n_workers = mp.cpu_count()
    else:
        try:
            n_workers = int(args.workers)
        except:
            n_workers = 1

    validator = RollingPortfolioValidator(
        timeframe=args.timeframe,
        window_months=args.window_months,
        step_months=args.step_months,
        results_dir=args.results_dir,
        output_dir=args.output_dir,
        n_workers=n_workers,
        penetration_threshold=args.penetration_threshold,
        min_recommend_freq=args.min_recommend_freq,
        sorting_mode=args.sorting_mode,
        min_sharpe=args.min_sharpe,
        min_return=args.min_return,
        max_drawdown=args.max_drawdown,
        correlation_threshold=args.correlation_threshold,
        min_strategies=args.min_strategies,
        max_strategies=args.max_strategies
    )

    results = validator.run_rolling_validation(
        top_n_per_window=args.top_n,
        use_parallel=(n_workers > 1)
    )

    validator.generate_report(results)


if __name__ == '__main__':
    main()
